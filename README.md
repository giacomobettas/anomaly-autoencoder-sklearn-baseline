# ðŸ§  Autoencoder-Based Anomaly Detection (scikit-learn Baseline)

This repository contains an early iteration of a video-based anomaly detection project for elderly home video surveillance, developed as part of my thesis internship for the *Master in Data Analysis for Business Intelligence and Data Science*.

The goal of this iteration is to implement a **lightweight, interpretable baseline** using:

- **scikit-learn** for an autoencoder built on `MLPRegressor`
- **OpenCV** for image loading and resizing
- **NumPy** for array operations
- **Matplotlib** for visualizing reconstruction errors

Later iterations of the project (not in this repo) extended the idea with deep learning, data generators, YOLO-based person detection, and face recognition.  
This repository focuses deliberately on the first version as a didactic baseline.

---

## ðŸ”§ Core Idea

1. Images are organized by **person** in `train/` and `test/` folders.
2. A scikit-learn **autoencoder** learns to reconstruct "normal" frames.
3. The **reconstruction error** (mean squared error per frame) is used as an anomaly score.
4. By analyzing reconstruction error distributions, we can:
   - Detect frames that behave differently from the training data.
   - Compute **per-person anomaly rates** and compare them.

---

## ðŸ“ Repository Structure

```text
anomaly-autoencoder-sklearn-baseline/
â”‚
â”œâ”€ src/                               # Core source code (scikit-learn baseline)
â”‚  â”œâ”€ __init__.py                     # Makes src a package
â”‚  â”œâ”€ data_loader.py                  # Loads grayscale images by person
â”‚  â”œâ”€ preprocess.py                   # Min-max scaling + flattening utilities
â”‚  â”œâ”€ model.py                        # SklearnAutoencoder wrapper around MLPRegressor
â”‚  â”œâ”€ train.py                        # Train autoencoder on data/train
â”‚  â”œâ”€ evaluate.py                     # Evaluate reconstruction errors on data/test
â”‚  â””â”€ infer.py                        # Infer anomaly score for a single image
â”‚
â”œâ”€ data/                              # Synthetic example dataset
â”‚  â”œâ”€ train/
â”‚  â”‚  â”œâ”€ person1/
â”‚  â”‚  â”‚   â”œâ”€ frame000.jpg
â”‚  â”‚  â”‚   â”œâ”€ frame001.jpg
â”‚  â”‚  â”‚   â””â”€ frame002.jpg
â”‚  â”‚  â””â”€ person2/
â”‚  â”‚      â”œâ”€ frame000.jpg
â”‚  â”‚      â”œâ”€ frame001.jpg
â”‚  â”‚      â””â”€ frame002.jpg
â”‚  â”œâ”€ test/
â”‚  â”‚  â”œâ”€ person1/
â”‚  â”‚  â”‚   â”œâ”€ frame000.jpg
â”‚  â”‚  â”‚   â”œâ”€ frame001.jpg
â”‚  â”‚  â”‚   â””â”€ frame002.jpg
â”‚  â”‚  â””â”€ person2/
â”‚  â”‚      â”œâ”€ frame000.jpg
â”‚  â”‚      â”œâ”€ frame001.jpg
â”‚  â”‚      â””â”€ frame002.jpg
â”‚  â””â”€ README.md                       # Explanation of expected data structure
â”‚
â”œâ”€ scripts/                           # Utility scripts
â”‚  â””â”€ create_synthetic_dataset.py     # Script for generating synthetic example data
â”‚
â”œâ”€ tests/                             # Basic smoke testing
â”‚  â””â”€ test_smoke.py                   # Ensures model builds, trains, reconstructs
â”‚
â”œâ”€ notebooks/
â”‚  â””â”€ demo_colab.ipynb                # Google Colab demo notebook to run the pipeline
â”‚
â”œâ”€ media/                             # Reconstruction error plots (for README)
â”‚  â”œâ”€ fall_video_21_error.png
â”‚  â”œâ”€ fall_video_68_error.png
â”‚  â””â”€ fall_video_test2-1_error.png
â”‚
â”œâ”€ models/                            # (Generated at runtime) Saved model + scaler
â”‚
â”œâ”€ requirements.txt                   # scikit-learn OpenCV, numpy, matplotlib, joblib, pytest
â”œâ”€ .gitignore                         # Ignore caches, environments, models, logs
â”œâ”€ LICENSE                            # MIT License
â””â”€ README.md                          # Project documentation (this file)

```

---

## âš™ï¸ Installation

Clone the repository:

```bash
git clone https://github.com/giacomobettas/anomaly-autoencoder-sklearn-baseline.git
cd anomaly-autoencoder-sklearn-baseline
```

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Basic Usage (Local)

### 1. Prepare the dataset

Follow the structure described in `data/README.md`, for example:

```text
data/
â”œâ”€ train/
â”‚  â”œâ”€ person1/
â”‚  â”œâ”€ person2/
â””â”€ test/
   â”œâ”€ person1/
   â”œâ”€ person2/
```

Each folder contains `.jpg` / `.png` images. Resolution doesn't matter: they will be resized to 64Ã—64 grayscale.

### 2. Train the autoencoder

```bash
python -m src.train --train_dir data/train \
    --model_path models/autoencoder.pkl \
    --scaler_path models/scaler.pkl
```

### 3. Evaluate on test set

```bash
python -m src.evaluate --test_dir data/test \
    --model_path models/autoencoder.pkl \
    --scaler_path models/scaler.pkl \
    --threshold_percentile 99.0
```

This prints:
- Global anomaly rate
- Per-person anomaly rate
- A histogram of reconstruction errors with the chosen threshold

### 4. Single-image inference

```bash
python -m src.infer \
    --image_path path/to/image.jpg \
    --model_path models/autoencoder.pkl \
    --scaler_path models/scaler.pkl \
    --threshold 0.01
```

---

## ðŸ’» Google Colab Usage

A ready-to-use Colab notebook is provided under `notebooks/demo_colab.ipynb`.

Typical workflow inside Colab:

1. Mount Google Drive (optional) if your dataset is in Drive.
2. Clone this repository inside Colab.
3. Install dependencies from `requirements.txt`.
4. Set dataset paths (`data/train`, `data/test`) according to your setup.
5. Run the training and evaluation commands directly from the notebook.

See the notebook cells and comments for a step-by-step explanation.

---

## ðŸ§ª Testing

To run the smoke test:

```bash
pytest tests/
```

This checks that the autoencoder can be built, trained briefly, and used for reconstruction on a tiny random dataset.

---

# ðŸ“Š Baseline Results on the UniversitÃ© de Bourgogne Fall Detection Dataset

This early scikit-learn autoencoder was tested on the
[**UniversitÃ© de Bourgogne Europe - Fall Detection Dataset**](https://imvia.ube.fr/en/database/fall-detection-dataset-2.html)

This dataset contains controlled indoor scenes including **fall events**, and aligns naturally with the goal of anomaly detection for **elferly home video surveillance** â€” the core objective of my thesis project.

During early Colab experiments, reconstruction error was plotted frame-by-frame to understand how well the MLPRegressor-based autoencoder responds to falls.

The results showed **high reconstruction error throughout videos**, but **consistent and pronounced spikes during fall events**.
This demonstrates that the baseline model was able to capture anomalies in principle, but remained **too weak and noisy for reliable detection in real-world settings**.

---

## ðŸ“ˆ Example Reconstruction Error Plots

![Reconstruction Error - Video 21](media/fall_video_21_error.png)

---

![Reconstruction Error - Video 68 (validation)](media/fall_video_68_error.png)

---

![Reconstruction Error - Test 2-1](media/fall_video_test2-1_error.png)

---

## ðŸ“Œ Interpretation

Across all videos:

* Reconstruction error remains **consistently elevated**, indicating the model struggles to reconstruct normal video frames with precision.
* Anomaly (fall) events produce **clear, sharp spikes** in reconstruction error.
* While promising, the model is **far from deployment-ready** due to:

  * high noise
  * poor generalization
  * sensitivity to lighting and motion
  * the limitations of a shallow MLPRegressor

These results provided valuable insight:

> **The baseline autoencoder was suboptimal but informative, showing the need for deeper models, improved training strategies, and more robust datasets.**

This motivated the transition to:

* âœ” **Deep convolutional autoencoders (TensorFlow/Keras)**
* âœ” **Data generators for stable long training sessions (Colab runtime compatible)**
* âœ” **Checkpointing and resuming training**
* âœ” **YOLO-based person detection for region-of-interest extraction**
* âœ” **Face recognition for person-specific anomaly tracking**
* âœ” **A more complete and varied dataset**

---

## ðŸ“š Notes

This repository represents a **baseline iteration** from my thesis project in the **Master in Data Analysis for Business Intelligence and Data Science**.

It is intentionally simple and scikit-learn-based, focusing on clarity and structure.

More advanced deep learning-based versions (with YOLO and face recognition) are part of later iterations and will live in separate repositories.
